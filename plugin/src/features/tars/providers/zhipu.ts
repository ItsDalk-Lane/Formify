import OpenAI from 'openai'
import { t } from 'tars/lang/helper'
import { BaseOptions, Message, ResolveEmbedAsBinary, SendRequest, Vendor } from '.'
import { DebugLogger } from '../../../utils/DebugLogger'
import { CALLOUT_BLOCK_START, CALLOUT_BLOCK_END } from './utils'

export type ZhipuThinkingType = 'enabled' | 'disabled' | 'auto'

export const ZHIPU_THINKING_TYPE_OPTIONS: { value: ZhipuThinkingType; label: string; description: string }[] = [
	{ value: 'disabled', label: 'ç¦ç”¨', description: 'ç¦ç”¨æ¨ç†ï¼Œç›´æ¥å›ç­”' },
	{ value: 'enabled', label: 'å¯ç”¨', description: 'å§‹ç»ˆå¯ç”¨æ·±åº¦æ¨ç†' },
	{ value: 'auto', label: 'è‡ªåŠ¨', description: 'æ¨¡å‹è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦ä½¿ç”¨æ¨ç†' }
]

export const DEFAULT_ZHIPU_THINKING_TYPE: ZhipuThinkingType = 'auto'

export const ZHIPU_REASONING_MODELS = ['glm-4.6', 'glm-4.5', 'glm-4.5v']

export const isReasoningModel = (model: string): boolean => {
	return ZHIPU_REASONING_MODELS.includes(model)
}

export interface ZhipuOptions extends BaseOptions {
	enableWebSearch: boolean
	enableReasoning: boolean
	thinkingType: ZhipuThinkingType
}

const sendRequestFunc = (settings: ZhipuOptions): SendRequest =>
	async function* (messages: Message[], controller: AbortController, _resolveEmbedAsBinary: ResolveEmbedAsBinary) {
		const { parameters, ...optionsExcludingParams } = settings
		const options = { ...optionsExcludingParams, ...parameters }
		const { apiKey, baseURL, model, enableWebSearch, enableReasoning, thinkingType, ...remains } = options
		if (!apiKey) throw new Error(t('API key is required'))
		DebugLogger.debug('zhipu options', { baseURL, apiKey, model, enableWebSearch, enableReasoning, thinkingType })

		const client = new OpenAI({
			apiKey: apiKey,
			baseURL,
			dangerouslyAllowBrowser: true
		})

		const tools = (enableWebSearch
			? [
					{
						type: 'web_search',
						web_search: {
							enable: true
						}
					}
				]
			: []) as object[] as OpenAI.Chat.Completions.ChatCompletionTool[] // hack, because the zhipu-ai function call type definition is different from openai's type definition

		// æ„å»ºè¯·æ±‚å‚æ•°
		const requestParams: any = {
			model,
			messages,
			stream: true,
			tools: tools,
			...remains
		}

		// æ·»åŠ æ¨ç†é…ç½®
		if (enableReasoning && isReasoningModel(model) && thinkingType !== 'disabled') {
			requestParams.thinking = {
				type: thinkingType
			}
		}

		const stream = await client.chat.completions.create(requestParams, {
			signal: controller.signal
		})

		let reasoningActive = false
		let reasoningBuffer = ''
		let blockStarted = false

		for await (const part of stream as any) {
			const delta = part.choices[0]?.delta

			// å¤„ç†æ¨ç†å†…å®¹ï¼ˆå‚è€ƒå®˜æ–¹æ–‡æ¡£çš„ reasoning_content å­—æ®µï¼‰
			// åªæœ‰åœ¨ç”¨æˆ·å¯ç”¨æ¨ç†åŠŸèƒ½æ—¶æ‰å¤„ç†æ¨ç†å†…å®¹
			if (enableReasoning && thinkingType !== 'disabled' && delta?.reasoning_content) {
				const reasoningText = delta.reasoning_content
				if (reasoningText) {
					if (!reasoningActive) {
						reasoningActive = true
						reasoningBuffer = 'ğŸ¤” **æ¨ç†è¿‡ç¨‹ï¼š** '
						blockStarted = false
					}
					reasoningBuffer += reasoningText.replace(/\n/g, '\n> ')

					// ç¼“å†²åˆ°ä¸€å®šé•¿åº¦æˆ–åŒ…å«å¥å·æ—¶æ‰è¾“å‡ºï¼Œå‡å°‘ yield é¢‘ç‡
					if (reasoningBuffer.length > 50 || reasoningText.includes('ã€‚') || reasoningText.includes('.')) {
						if (!blockStarted) {
							yield CALLOUT_BLOCK_START + reasoningBuffer
							blockStarted = true
						} else {
							yield reasoningBuffer
						}
						reasoningBuffer = ''
					}
				}
				continue
			}

			// å¤„ç†æ™®é€šæ–‡æœ¬å†…å®¹
			const text = delta?.content
			if (text) {
				// å¦‚æœæœ‰ç¼“å†²çš„æ¨ç†å†…å®¹ï¼Œå…ˆè¾“å‡º
				if (reasoningBuffer && reasoningActive) {
					if (!blockStarted) {
						yield CALLOUT_BLOCK_START + reasoningBuffer
					} else {
						yield reasoningBuffer
					}
					reasoningBuffer = ''
					yield CALLOUT_BLOCK_END
					blockStarted = false
				}

				if (reasoningActive) {
					reasoningActive = false
					yield '\n\n**å›ç­”ï¼š**\n\n' + text
				} else {
					yield text
				}
			}
		}

		// å¤„ç†å‰©ä½™çš„æ¨ç†å†…å®¹
		if (reasoningBuffer && reasoningActive) {
			if (!blockStarted) {
				yield CALLOUT_BLOCK_START + reasoningBuffer
			} else {
				yield reasoningBuffer
			}
			yield CALLOUT_BLOCK_END
		}
	}


const models = ['glm-4-plus', 'glm-4-air', 'glm-4-airx', 'glm-4-long', 'glm-4-flash', 'glm-4-flashx', 'glm-4.6', 'glm-4.5', 'glm-4.5v']

export const zhipuVendor: Vendor = {
	name: 'Zhipu',
	defaultOptions: {
		apiKey: '',
		baseURL: 'https://open.bigmodel.cn/api/paas/v4/',
		model: models[0],
		enableWebSearch: false,
		enableReasoning: false,
		thinkingType: DEFAULT_ZHIPU_THINKING_TYPE,
		parameters: {}
	} as ZhipuOptions,
	sendRequestFunc,
	models,
	websiteToObtainKey: 'https://open.bigmodel.cn/',
	capabilities: ['Text Generation', 'Web Search', 'Reasoning']
}

